# GitHub Copilot Instructions - Rob√¥ de Download Neo

## üìã Contexto do Projeto

Este √© um sistema de automa√ß√£o web empresarial que realiza downloads automatizados de relat√≥rios de um sistema corporativo e os processa para envio a APIs do NocoDB. O projeto utiliza Selenium para automa√ß√£o web, pandas para processamento de dados, e tem um sistema robusto de agendamento e retry.

## üéØ Objetivos Principais

- **Automa√ß√£o Web**: Login automatizado com 2FA/OTP e navega√ß√£o por interface Vaadin
- **Download de Relat√≥rios**: Extra√ß√£o de dados de Produ√ß√£o, Atividades e Status de Atividades
- **Processamento de Dados**: Parse flex√≠vel de arquivos Excel com mapeamento din√¢mico
- **Integra√ß√£o API**: Envio em batches para NocoDB com retry e logging detalhado
- **Execu√ß√£o Agendada**: Runs a cada 30 minutos entre 8h-22h

## üèóÔ∏è Arquitetura e Componentes

### Estrutura Principal
```
app.py              # Aplica√ß√£o principal com toda a l√≥gica
bases/              # üìÅ NOVO (Fase 4): Pasta obrigat√≥ria para JSONs
  ‚îú‚îÄ‚îÄ map_relative.json
  ‚îú‚îÄ‚îÄ nocodb_map.json
  ‚îú‚îÄ‚îÄ sql_map.json
downloads/          # üìÅ Arquivos Excel baixados
logs/               # üìÅ Logs estruturados em JSONL
tests/              # Suite completa de testes
.env                # Configura√ß√µes sens√≠veis
```

**Importante (Fase 4):** Todos os JSONs **DEVEM** estar em `\bases\`. Sem fallback para raiz do projeto.

### Tecnologias Core
- **Selenium WebDriver** (Chrome/Edge)
- **Pandas** para processamento Excel
- **Requests** para APIs HTTP
- **Schedule** para agendamento
- **PyInstaller** para empacotamento

## üîß Padr√µes de C√≥digo

### 1. Fun√ß√£o de Elementos Web
```python
def encontrar_elemento(driver, xpath, referencia_map=None, tempo=10):
    # Sempre usar WebDriverWait com EC
    # Incluir referencia_map para logs
    # Salvar screenshot para debug
```

### 2. XPaths Relativos
- Usar `map_relative.json` para todos os seletores
- XPaths absolutos robustos para framework Vaadin
- Refer√™ncias organizadas hierarquicamente (login.username_field, atividades.panel)

### 3. Processamento de Dados
```python
def parse_export_producao(file_path):
    # Usar pandas.read_excel()
    # Normalizar headers (acentos, pontua√ß√£o)
    # Mapeamento tolerante com nocodb_map.json
    # Formato de data: "%Y-%m-%d %H:%M:%S"
```

### 4. Envio de APIs
```python
def post_records_to_mssql(records, table_name='producao', file_name=None):
    # Conectar ao SQL Server usando pyodbc
    # Usar sql_map.json para determinar tabela e colunas
    # Processar em batches (BATCH_SIZE)
    # NOVO (Fase 6): Por-RECORD processing com IntegrityError handling
    #   - Cada registro processado individualmente
    #   - IntegrityError + PRIMARY KEY = IGNORA (n√£o retry)
    #   - Outro erro = tenta retry com backoff
    #   - Contadores: batch_success_count, batch_duplicate_count, batch_error_count
    # NOVO: Rastreamento de linha (number_line) para cada registro
    #   - _line_number adicionado em parse_export_producao (linha do Excel)
    #   - _file_name adicionado (nome do arquivo)
    #   - Logs de erro mostram: qual linha, qual arquivo, qual dado falhou
    # Logging em JSONL estruturado
    # NOVO (Fase 5): Taxa de sucesso em porcentagem
    # Suporte a DRY_RUN
```

### 5. Download com Retry Autom√°tico (Novo - Fase 8)
```python
def exportAtividadesStatus(driver):
    """Exporta com retry autom√°tico (3 tentativas, 1 min delay)."""
    max_tentativas = 3
    delay_segundos = 60
    
    for tentativa in range(1, max_tentativas + 1):
        try:
            # L√≥gica de export
            realizar_download(driver)
            logger.info("‚úÖ Arquivo baixado com sucesso!")
            return  # Exit imediato se sucesso
        except Exception as e:
            if tentativa < max_tentativas:
                logger.warning(f"‚ö†Ô∏è Tentativa {tentativa}/{max_tentativas}: aguardando {delay_segundos}s...")
                time.sleep(delay_segundos)
            else:
                logger.error(f"‚ùå FALHA FINAL ap√≥s {max_tentativas} tentativas")
                raise
```

**Padr√£o de retry para downloads (exportAtividadesStatus, exportAtividades, exportProducao):**
- 3 tentativas total
- 60 segundos de delay entre tentativas
- Retorna imediatamente se sucesso
- Levanta exception apenas ap√≥s todas as tentativas falharem
- **Ver:** `docs/ESTRATEGIA_RETRY_DOWNLOADS.md` para detalhes completos

### 6. Logging Estruturado
- Console + arquivo para execu√ß√£o
- JSONL para dados enviados/falhas (NOVO Fase 5: com batch_num, record_num)
- **NOVO: Rastreamento de origem** (file, line_number para cada registro)
  - Cada registro sabe sua linha original no Excel
  - Logs de erro incluem: `arquivo.xlsx linha 42`
  - JSONL inclui field `source: {file, line}` para auditoria
- Screenshots autom√°ticos de elementos
- Resumos de envio com m√©tricas e taxa de sucesso em %
- Emojis para indicadores visuais (‚úÖ, ‚ùå, ‚ö†Ô∏è, üìä)

## üõ†Ô∏è Conven√ß√µes de Desenvolvimento

### Vari√°veis de Ambiente
```env
# Sistema alvo
SYS_URL, SYS_USERNAME, SYS_PASSWORD, SYS_SECRET_OTP

# Browser e timeouts
BROWSER=chrome, HEADLESS=false, TIMEOUT_DOWNLOAD=60

# SQL Server
DB_SERVER, DB_DATABASE, DB_USERNAME, DB_PASSWORD, DB_DRIVER

# Configura√ß√µes de envio
BATCH_SIZE=25, POST_RETRIES=3, BACKOFF_BASE=1.5
```

### Tratamento de Erros
- **ElementClickInterceptedException**: Tentar ESC para fechar overlays
- **StaleElementReferenceException**: Re-encontrar elemento
- **PermissionError**: Log warning e continuar (arquivos em uso)
- **API failures**: Retry com backoff exponencial
- **IntegrityError + PRIMARY KEY (Novo Fase 6):** IGNORA (√© duplicata, n√£o retry)
  - Per-record processing: continua batch mesmo se h√° duplicata
  - Logging: debug level mostra qual duplicata
  - Contadores: batch_success_count, batch_duplicate_count, batch_error_count

### Estrutura de Testes
```python
# tests/test_parse_*.py - Parse Excel -> JSON
# tests/test_post_*.py - JSON -> API com --dry-run
# Usar argparse para flexibilidade
# Gerar timestamps em arquivos de sa√≠da
```

## üìä Tipos de Dados

### Relat√≥rios Suportados
1. **ExportacaoProducao.xlsx**: Dados de pedidos, clientes, produtos
2. **Exportacao Atividade.xlsx**: Atividades operacionais
3. **Exportacao Status.xlsx**: Hist√≥rico de status e movimenta√ß√µes

### Mapeamento Flex√≠vel
- Headers normalizados (sem acentos, lowercase)
- Matching tolerante por substring
- Campos extras concatenados em "TAGS"
- Valores None/NaN convertidos para string vazia
- Mapeamento SQL em `sql_map.json` com tabelas e colunas
- **JSONs carregados EXCLUSIVAMENTE de `\bases\`** (Novo Fase 4)
  - Sem fallback para raiz do projeto
  - Falha early com mensagem clara se n√£o encontrados

## üîÑ Fluxo de Execu√ß√£o Padr√£o

1. **Inicializa√ß√£o**: Validar .env, limpar downloads antigos
2. **Login**: Credenciais + OTP com retry autom√°tico
3. **Navega√ß√£o**: Abrir sidebar, acessar pain√©is espec√≠ficos
4. **Downloads**: Atividades Status (90d) ‚Üí Atividades (90d) ‚Üí Produ√ß√£o (92d, dia 1)
5. **Processamento**: Parse imediato ap√≥s download
6. **Envio**: Inserts em SQL Server com batches e retry
7. **Agendamento**: Pr√≥xima execu√ß√£o em 30min

## üß™ Estrat√©gia de Testes

### Parse Testing
```python
python tests/test_parse_atividades.py [arquivo_opcional]
# Gera: tests/json/parsed_atividades_YYYYMMDD_HHMMSS.json
```

### API Testing
```python
python tests/test_post_atividades.py --dry-run --batch-size 10
# Valida sem enviar, logs detalhados
```

## üö® Pontos de Aten√ß√£o

### Interface Web (Vaadin)
- Framework Vaadin com elementos customizados
- XPaths podem quebrar com updates da UI
- Overlays/modals podem interceptar clicks
- Sempre usar `ActionChains` para clicks complexos

### Arquivos Excel
- Estrutura pode variar entre vers√µes do sistema
- Headers podem ter pequenas diferen√ßas
- Datas em formatos diversos (DD/MM/YYYY, timestamps)
- Campos vazios devem ser tratados como strings vazias

### SQL Server (Migra√ß√£o de NocoDB)
- Conex√£o via ODBC com autentica√ß√£o SQL
- Credenciais no .env: DB_SERVER, DB_DATABASE, DB_USERNAME, DB_PASSWORD
- Inserts em batches configur√°veis (BATCH_SIZE)
- Tratamento de caracteres especiais em strings
- √çndices nas tabelas melhoram performance
- Tentativas de conex√£o com retry + backoff exponencial
- Logging estruturado em JSONL para auditoria
- **NOVO (Fase 6): Tratamento de duplicatas (PRIMARY KEY violations)**
  - Per-record processing evita perda de lote inteiro
  - IntegrityError + PRIMARY KEY = IGNORA (n√£o retry)
  - Taxa de sucesso reflete resultado REAL (n√£o artificialmente baixa)
- **NOVO: Rastreamento de linha do Excel**
  - Cada registro carrega `_line_number` (linha do Excel original)
  - Cada registro carrega `_file_name` (nome do arquivo)
  - Logs de erro mostram: qual linha, qual arquivo, qual dado
  - JSONL inclui `source: {file, line}` para auditoria
  - Permite rastrear facilmente erro at√© origem no Excel

## üí° Melhores Pr√°ticas para Desenvolvimento

### Ao Modificar XPaths
1. Testar em ambiente real
2. Usar `gerar_xpath_relativo.py` para novos elementos
3. Manter refer√™ncias organizadas no JSON
4. Salvar screenshots para documenta√ß√£o

### Ao Adicionar Novos Relat√≥rios
1. Criar entrada em `nocodb_map.json`
2. Implementar fun√ß√£o `parse_*` espec√≠fica
3. Adicionar URL da tabela no .env
4. Criar testes correspondentes

### Ao Debuggar
1. Verificar `element_screenshots/` para capturas
2. Analisar logs JSONL com `jq` ou similar
3. Usar `--dry-run` para validar sem side effects
4. Screenshots manuais com `salvar_screenshot_elemento()`
5. Verificar conex√£o SQL Server em `logs/sent_records_*.jsonl`

### Deploy e Manuten√ß√£o
- Usar `empacotar_robo_neo.bat` para builds
- Incluir todos os JSONs e .env no pacote
- Testar em ambiente similar ao produ√ß√£o
- Monitorar logs de `envios_resumo.jsonl`

### Tratamento de Duplicatas (NOVO - Fase 6)
- **Quando:** INSERT falhar com `pyodbc.IntegrityError` + "PRIMARY KEY"
- **O que fazer:** IGNORA (n√£o tenta retry)
- **O que N√ÉO fazer:** N√£o aumentar POST_RETRIES (n√£o resolve)
- **Logging:** Debug level apenas
- **Impacto:** Batch continua (24/25 ao inv√©s de 0/25)
- **Taxa sucesso:** Agora reflete realidade (n√£o artifical 0% ou 100%)

## üìö Rotina de Atualiza√ß√£o de Documenta√ß√£o

### Quando Modificar C√≥digo
**IMPORTANTE:** Toda mudan√ßa no c√≥digo `app.py` ou arquivos-chave **DEVE** ser documentada. Por√©m, **N√ÉO crie novo `.md`** - atualize os arquivos existentes!

### Mapeamento C√≥digo ‚Üí Documenta√ß√£o

| Aspecto do C√≥digo | Arquivo a Atualizar | Se√ß√£o/T√≥pico |
|------------------|-------------------|-------------|
| **Arquitetura, fluxo, padr√µes** | `docs/ARQUITETURA_E_API.md` | Se√ß√£o correspondente |
| **Instala√ß√£o, setup, deploy** | `docs/INSTALACAO_E_DEPLOY.md` | "Fase X" ou "Setup" |
| **Erros, exceptions, bugs** | `docs/TROUBLESHOOTING.md` | "Problemas Comuns" |
| **Navega√ß√£o, √≠ndice de t√≥picos** | `docs/INDICE_DOCUMENTACAO.md` | √çndice principal |
| **Padr√µes de c√≥digo, conven√ß√µes** | `.github/copilot-instructions.md` | "Padr√µes de C√≥digo" |

### Rotina Passo-a-Passo

**1Ô∏è‚É£ Voc√™ fez mudan√ßa no c√≥digo:**
```
Exemplo: Adicionou novo tipo de retry exponencial em app.py
```

**2Ô∏è‚É£ Identifique qual `.md` documenta isso:**
```
‚Üí Padr√£o de c√≥digo = copilot-instructions.md
‚Üí OU Arquitetura = ARQUITETURA_E_API.md
```

**3Ô∏è‚É£ Procure a se√ß√£o relevante NO ARQUIVO EXISTENTE:**
```
N√ÉO crie novo .md chamado "NOVO_RETRY_EXPONENCIAL.md"
‚Üì
Procure em ARQUITETURA_E_API.md a se√ß√£o "Tratamento de Erros"
ou "Envio de APIs" que fale sobre retry
```

**4Ô∏è‚É£ Atualize a se√ß√£o encontrada:**
```
Use replace_string_in_file para atualizar a se√ß√£o
Mantenha a estrutura original
Adicione seus detalhes √† se√ß√£o existente
```

**5Ô∏è‚É£ Se nenhuma se√ß√£o existir:**
```
EXCE√á√ÉO: Se n√£o houver se√ß√£o relevante em nenhum .md
‚Üí Crie uma NOVA SE√á√ÉO dentro do .md mais apropriado
‚Üí N√ÉO crie um novo arquivo .md
‚Üí Exemplo: Se √© novo erro, adicione em TROUBLESHOOTING.md
```

### Exemplos de Aplica√ß√£o

**Exemplo 1: Novo padr√£o de logging**
```
Mudan√ßa: app.py agora usa logger.info() com emoji üìä
Arquivo: .github/copilot-instructions.md
Se√ß√£o: "Logging Estruturado"
A√ß√£o: Atualizar exemplo de c√≥digo nessa se√ß√£o
```

**Exemplo 2: Novo erro de conex√£o SQL**
```
Mudan√ßa: Novo erro `[HY001]` adicionado
Arquivo: docs/TROUBLESHOOTING.md
Se√ß√£o: "Problemas Comuns"
A√ß√£o: Adicionar novo erro com solu√ß√£o nessa se√ß√£o
```

**Exemplo 3: Nova fase de desenvolvimento**
```
Mudan√ßa: Fase 7 implementada com cache
Arquivo: docs/INSTALACAO_E_DEPLOY.md
Se√ß√£o: "Fase 7: [Nome]"
A√ß√£o: Adicionar nova se√ß√£o Fase 7 ap√≥s Fase 6
```

### ‚ö†Ô∏è Regras de Ouro

1. **N√ÉO criar arquivo `.md` novo** por mudan√ßa de c√≥digo
   - Exce√ß√£o: Documenta√ß√£o completamente fora do escopo atual (muito rara)

2. **SEMPRE verificar docs existentes** antes de escrever
   - Use `grep` ou leitura para encontrar se√ß√£o relevante
   - Se n√£o achar, v√° para se√ß√£o "gen√©rica" (ex: Troubleshooting)

3. **Manter estrutura original** do documento
   - N√£o reorganize se√ß√µes existentes
   - N√£o remova conte√∫do obsoleto (marque como ‚ö†Ô∏è DEPRECATED se necess√°rio)

4. **Links internos** devem apontar para arquivo e se√ß√£o corretos
   - Exemplo: `[Ver em TROUBLESHOOTING.md](../docs/TROUBLESHOOTING.md)`

5. **Data de atualiza√ß√£o** no final do arquivo
   - Exemplo: `**√öltima atualiza√ß√£o:** 28 de outubro de 2025`

### Vantagens dessa Rotina

‚úÖ **Documenta√ß√£o n√£o fica dispersa** em 20+ arquivos  
‚úÖ **Usu√°rios sabem exatamente onde procurar** (mapeamento claro)  
‚úÖ **F√°cil manuten√ß√£o** (tudo organizado em 5 arquivos)  
‚úÖ **Sem duplica√ß√£o** de informa√ß√£o entre docs  
‚úÖ **Escal√°vel** (crescer sem poluir reposit√≥rio)  

## üéØ Objetivos de Qualidade

- **Robustez**: Zero falhas por mudan√ßas menores na UI
- **Observabilidade**: Logs completos para debugging
- **Flexibilidade**: Configura√ß√£o externa para adapta√ß√µes
- **Testabilidade**: Suite completa com dry-run
- **Manutenibilidade**: C√≥digo modular e bem documentado

---

*Este projeto segue padr√µes de automa√ß√£o web empresarial com foco em confiabilidade e manutenibilidade. Sempre priorize logging detalhado e tratamento robusto de exce√ß√µes.*